"""
File which contains the main backbone of the CNVizard, that formats the input files
@author: Jeremias Krause, Carlos Classen, Matthias Begemann, Florian Kraft
@company: UKA Aachen (RWTH)
@mail: jerkrause@ukaachen.de
"""
import streamlit as st
import pandas as pd
import os


class CNVVisualizer:
    """
    Class used to format the imported .cnr dataframe, bintest dataframe, and the reference dataframe.
    """

    def __init__(
        self,
        reference_db: pd.DataFrame,
        cnr_db: pd.DataFrame,
        bintest_db: pd.DataFrame = None,
    ):
        """
        Constructor of the Class CNVVisualizer.

        Args:
            reference_db (pd.DataFrame): Contains the aggregated information of multiple .cnr files (used for frequency filtering and plots).
            cnr_db (pd.DataFrame): Contains the index patient's CNV information, created by importing the .cnr file generated by CNVkit.
            bintest_db (pd.DataFrame, optional): Contains the index patient's bintest CNV information, created by importing the bintest file generated by CNVkit. Defaults to None.
        """
        self.reference_db = reference_db
        self.cnr_db = cnr_db
        self.bintest_db = bintest_db if bintest_db is not None else pd.DataFrame()

    def explode_df(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Splits the 'gene' column of a pandas DataFrame on a comma and subsequently explodes the column.

        Args:
            df (pd.DataFrame): DataFrame to be exploded.

        Returns:
            pd.DataFrame: Exploded DataFrame.
        """
        df = df.copy()  # To avoid SettingWithCopyWarning
        df["gene"] = df["gene"].str.split(",")
        df = df.explode("gene")
        return df

    def prepare_cnv_table(self, df: pd.DataFrame, omim_df: pd.DataFrame) -> pd.DataFrame:
        """
        Processes and adds relevant information to the .cnr/bintest DataFrame.

        Steps:
        1. Drops antitarget entries.
        2. Applies the reverse function of log2 for easier interpretation.
        3. Reorders columns.
        4. Translates log2-value into call information.
        5. Merges with OMIM DataFrame.
        6. Fills None entries.

        Args:
            df (pd.DataFrame): .cnr/bintest DataFrame to be processed.
            omim_df (pd.DataFrame): OMIM DataFrame created by importing the omim.txt file.

        Returns:
            pd.DataFrame: Extended and reordered pandas DataFrame.
        """
        df = df.copy()  # To avoid SettingWithCopyWarning
        df.drop(df[df["gene"].str.contains("Antitarget")].index, inplace=True)
        df["CN"] = 2 ** df["log2"]
        df["gene"] = df["gene"].str.split("_")
        df["exon"] = df["gene"].str[1].astype(int)
        df["gene"] = df["gene"].str[0]
        cols = df.columns.tolist()
        cols = cols[0:4] + cols[-1:] + cols[5:6] + cols[6:7] + cols[4:5] + cols[7:-1]
        df = df[cols]
        df.insert(loc=7, column="call", value="")
        df.loc[df["log2"] <= -1.1, "call"] = int(0)
        df.loc[(df["log2"] <= -0.4) & (df["log2"] > -1.1), "call"] = int(1)
        df.loc[(df["log2"] <= 0.3) & (df["log2"] > -0.4), "call"] = int(2)
        df.loc[df["log2"] > 0.3, "call"] = int(3)
        df = pd.merge(df, omim_df, on="gene", how="left")
        df["comments"] = "."
        return df

    def prepare_parent_cnv(self, parent_df: pd.DataFrame) -> pd.DataFrame:
        """
        Processes the index patient's parental .cnr DataFrames for trio visualization.

        Args:
            parent_df (pd.DataFrame): Parental .cnr DataFrame.

        Returns:
            pd.DataFrame: Processed parental .cnr DataFrame.
        """
        parent_df = self.explode_df(parent_df)
        parent_df.drop(
            parent_df[parent_df["gene"].str.contains("Antitarget")].index, inplace=True
        )
        parent_df["CN"] = 2 ** parent_df["log2"]
        parent_df["gene"] = parent_df["gene"].str.split("_")
        parent_df["exon"] = parent_df["gene"].str[1].astype(int)
        parent_df["gene"] = parent_df["gene"].str[0]
        cols = parent_df.columns.tolist()
        cols = cols[0:4] + cols[-1:] + cols[5:6] + cols[6:7] + cols[4:5] + cols[7:-1]
        parent_df = parent_df[cols]
        parent_df.insert(loc=7, column="call", value="")
        parent_df.loc[parent_df["log2"] <= -1.1, "call"] = int(0)
        parent_df.loc[
            (parent_df["log2"] <= -0.4) & (parent_df["log2"] > -1.1), "call"
        ] = int(1)
        parent_df.loc[
            (parent_df["log2"] <= 0.3) & (parent_df["log2"] > -0.4), "call"
        ] = int(2)
        parent_df.loc[parent_df["log2"] > 0.3, "call"] = int(3)
        return parent_df

    def format_df(self, omim_path: str, selected_candi_path: str):
        """
        Imports and preprocesses the OMIM and candidate DataFrames.

        Args:
            omim_path (str): Path to omim.txt file.
            selected_candi_path (str): Path to selected candidate gene list file.

        Returns:
            tuple: (omim_df, candi_df, cnr_db, bintest_db)
        """
        # Load OMIM DataFrame
        if os.path.isfile(omim_path):
            omim_df = pd.read_csv(omim_path, header=0, delimiter="\t")
        else:
            omim_df = pd.DataFrame(columns=["gene", "OMIMG", "Disease", "OMIMP", "Inheritance"])
            omim_df.loc[0] = [".", ".", ".", ".", "."]

        # Load Candidate Genes DataFrame
        if os.path.isfile(selected_candi_path):
            candi_df = pd.read_csv(
                selected_candi_path, header=None, names=["gen"], delimiter="\t"
            )
        else:
            candi_df = pd.DataFrame(columns=["gen"])

        # Check if 'gene' column exists in cnr_db
        if "gene" not in self.cnr_db.columns:
            st.error("The column 'gene' is missing from the CNR DataFrame.")
            st.stop()

        # Process cnr_db
        self.cnr_db = self.explode_df(self.cnr_db)
        self.cnr_db = self.prepare_cnv_table(self.cnr_db, omim_df)
        gene_size = (
            self.cnr_db.groupby("gene")["gene"].size().reset_index(name="gene_size")
        )
        self.cnr_db = pd.merge(self.cnr_db, gene_size, on="gene", how="left")
        self.cnr_db = self.cnr_db.fillna(".")

        # Process bintest_db only if it's not empty
        if not self.bintest_db.empty:
            if "gene" not in self.bintest_db.columns:
                st.error("The column 'gene' is missing from the Bintest DataFrame.")
                st.stop()
            self.bintest_db = self.explode_df(self.bintest_db)
            self.bintest_db = self.prepare_cnv_table(self.bintest_db, omim_df)
            self.bintest_db = self.bintest_db.fillna(".")
        else:
            self.bintest_db = pd.DataFrame()

        return omim_df, candi_df, self.cnr_db, self.bintest_db

    def filter_for_deletions_hom(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Filters for homozygously deleted exons (call == 0).

        Args:
            df (pd.DataFrame): .cnr DataFrame.

        Returns:
            pd.DataFrame: DataFrame filtered for homozygously deleted exons.
        """
        df_del_hom = df[df["call"] == 0]
        return df_del_hom

    def filter_for_duplications(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Filters for duplicated exons (call == 3).

        Args:
            df (pd.DataFrame): .cnr DataFrame.

        Returns:
            pd.DataFrame: DataFrame filtered for duplicated exons.
        """
        df_dup = df[df["call"] == 3]
        return df_dup

    def filter_for_deletions(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Filters for heterozygously deleted exons (call == 1) and homozygously deleted exons (call == 0).

        Args:
            df (pd.DataFrame): .cnr DataFrame.

        Returns:
            pd.DataFrame: DataFrame filtered for deletions.
        """
        df_del = df[(df["call"] == 0) | (df["call"] == 1)]
        return df_del

    def prepare_filter_for_consecutive_cnvs(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Prepares DataFrame to filter for consecutively deleted/duplicated exons.

        Args:
            df (pd.DataFrame): .cnr DataFrame.

        Returns:
            pd.DataFrame: DataFrame with additional columns for consecutive CNV detection.
        """
        df = df.copy()  # To avoid SettingWithCopyWarning
        df["difference_previous"] = df.groupby("gene")["exon"].diff()
        df["difference_previous"] = df["difference_previous"].fillna(method="bfill")
        df["difference_next"] = df.groupby("gene")["exon"].diff(periods=-1)
        df["difference_next"] = df["difference_next"].fillna(method="ffill")
        return df

    def filter_for_consecutive_cnvs(
        self, df: pd.DataFrame, del_or_dup: str, del_size: int, dup_size: int
    ) -> pd.DataFrame:
        """
        Filters for consecutively deleted or duplicated exons.

        Args:
            df (pd.DataFrame): .cnr DataFrame annotated with consecutive CNVs.
            del_or_dup (str): Determines whether to filter for deletions ('del') or duplications ('dup').
            del_size (int): Minimum number of consecutive deletions.
            dup_size (int): Minimum number of consecutive duplications.

        Returns:
            pd.DataFrame: DataFrame filtered for consecutive deletions/duplications.
        """
        if del_size is None or del_size == "":
            del_size = 2
        if dup_size is None or dup_size == "":
            dup_size = 2
        del_size = int(del_size)
        dup_size = int(dup_size)

        if del_or_dup == "del":
            df_cons = df[
                (
                    ((df["call"] == 0) | (df["call"] == 1))
                    & (
                        (df["difference_previous"] == -1)
                        | (df["difference_previous"] == 1)
                    )
                )
                | (
                    ((df["call"] == 0) | (df["call"] == 1))
                    & ((df["difference_next"] == -1) | (df["difference_next"] == 1))
                )
            ]
            affected_size = (
                df_cons.groupby("gene")["gene"].size().reset_index(name="counts")
            )
            df_cons = pd.merge(df_cons, affected_size, on="gene", how="left")
            df_cons = df_cons[
                (df_cons["counts"] >= del_size)
                | (df_cons["gene_size"] == df_cons["counts"])
            ]
        else:
            df_cons = df[
                (
                    (df["call"] == 3)
                    & (
                        (df["difference_previous"] == -1)
                        | (df["difference_previous"] == 1)
                    )
                )
                | (
                    (df["call"] == 3)
                    & ((df["difference_next"] == -1) | (df["difference_next"] == 1))
                )
            ]
            affected_size = (
                df_cons.groupby("gene")["gene"].size().reset_index(name="counts")
            )
            df_cons = pd.merge(df_cons, affected_size, on="gene", how="left")
            df_cons = df_cons[
                (df_cons["counts"] >= dup_size)
                | (df_cons["gene_size"] == df_cons["counts"])
            ]
        return df_cons

    def filter_for_candi_cnvs(
        self, df: pd.DataFrame, candi_df: pd.DataFrame
    ) -> pd.DataFrame:
        """
        Filters for genes contained in the candidate gene list.

        Args:
            df (pd.DataFrame): .cnr DataFrame.
            candi_df (pd.DataFrame): Candidate gene DataFrame.

        Returns:
            pd.DataFrame: DataFrame filtered for candidate genes.
        """
        df = df.copy()  # To avoid SettingWithCopyWarning
        df["gene_upper"] = df["gene"].str.upper()
        candi_df["gen_upper"] = candi_df["gen"].str.upper()
        df["in_candidate_list"] = df["gene_upper"].isin(candi_df["gen_upper"])
        df_filter_candi = df[(df["in_candidate_list"]) & (df["call"] != 2)]
        return df_filter_candi

    def apply_filters(
        self,
        df: pd.DataFrame,
        start_selection: str,
        end_selection: str,
        depth_selection: str,
        weight_selection: str,
        chrom_selection: list,
        call_selection: list,
        log2_selection: str,
        gene_selection: list,
        chrom_list: list,
        call_list: list,
        gene_list: list,
        het_del_selection: str,
        hom_del_selection: str,
        dup_selection: str,
    ) -> pd.DataFrame:
        """
        Applies the predefined filters for the .cnr file.

        Args:
            df (pd.DataFrame): .cnr DataFrame.
            start_selection (str): Start coordinate (only works if end coordinate and one chromosome are selected).
            end_selection (str): End coordinate (only works if start coordinate and one chromosome are selected).
            depth_selection (str): Minimum depth.
            weight_selection (str): Minimum weight.
            chrom_selection (list): Chromosomes to display.
            call_selection (list): Calls to display.
            log2_selection (str): Minimum log2.
            gene_selection (list): Genes to display.
            chrom_list (list): List of all chromosomes.
            call_list (list): List of all possible calls.
            gene_list (list): List of all genes.
            het_del_selection (str): Maximum heterozygous deletion frequency.
            hom_del_selection (str): Maximum homozygous deletion frequency.
            dup_selection (str): Maximum duplication frequency.

        Returns:
            pd.DataFrame: Filtered DataFrame.
        """
        skip_start_end = False
        filtered_df = df.copy()
        filtered_df["chromosome"] = filtered_df["chromosome"].astype(str)
        filtered_df["call"] = filtered_df["call"].astype(int)
        filtered_df["gene"] = filtered_df["gene"].astype(str)
        filtered_df["depth"] = filtered_df["depth"].astype(float)
        filtered_df["weight"] = filtered_df["weight"].astype(float)
        filtered_df["log2"] = filtered_df["log2"].astype(float)
        filtered_df["start"] = filtered_df["start"].astype(int)
        filtered_df["end"] = filtered_df["end"].astype(int)
        filtered_df["het_del_frequency"] = filtered_df.get("het_del_frequency", pd.Series([0]*len(filtered_df))).astype(float)
        filtered_df["hom_del_frequency"] = filtered_df.get("hom_del_frequency", pd.Series([0]*len(filtered_df))).astype(float)
        filtered_df["dup_frequency"] = filtered_df.get("dup_frequency", pd.Series([0]*len(filtered_df))).astype(float)

        try:
            if start_selection and end_selection and len(chrom_selection) == 1:
                start_selection = int(start_selection)
                end_selection = int(end_selection)
            else:
                skip_start_end = True
        except ValueError:
            st.warning("Invalid start or end selection. Must be integers.")
            skip_start_end = True

        try:
            depth_selection = float(depth_selection) if depth_selection else -10000.0
        except ValueError:
            st.warning("Invalid depth selection. Must be a float.")
            depth_selection = -10000.0

        try:
            weight_selection = float(weight_selection) if weight_selection else -10000.0
        except ValueError:
            st.warning("Invalid weight selection. Must be a float.")
            weight_selection = -10000.0

        try:
            log2_selection = float(log2_selection) if log2_selection else -10000.0
        except ValueError:
            st.warning("Invalid log2 selection. Must be a float.")
            log2_selection = -10000.0

        try:
            het_del_selection = float(het_del_selection) if het_del_selection else 1.0
        except ValueError:
            st.warning("Invalid heterozygous deletion frequency. Must be a float.")
            het_del_selection = 1.0

        try:
            hom_del_selection = float(hom_del_selection) if hom_del_selection else 1.0
        except ValueError:
            st.warning("Invalid homozygous deletion frequency. Must be a float.")
            hom_del_selection = 1.0

        try:
            dup_selection = float(dup_selection) if dup_selection else 1.0
        except ValueError:
            st.warning("Invalid duplication frequency. Must be a float.")
            dup_selection = 1.0

        if not chrom_selection:
            chrom_selection = chrom_list
        if not call_selection:
            call_selection = call_list
        if not gene_selection:
            gene_selection = gene_list

        if skip_start_end:
            filtered_df = filtered_df[filtered_df["chromosome"].isin(chrom_selection)]
        else:
            filtered_df = filtered_df[
                (filtered_df["chromosome"].isin(chrom_selection))
                & (filtered_df["start"] >= start_selection)
                & (filtered_df["end"] <= end_selection)
            ]

        filtered_df = filtered_df[
            (filtered_df["call"].isin(call_selection))
            & (filtered_df["gene"].isin(gene_selection))
            & (filtered_df["depth"] >= depth_selection)
            & (filtered_df["weight"] >= weight_selection)
            & (filtered_df["log2"] >= log2_selection)
            & (filtered_df["het_del_frequency"] <= het_del_selection)
            & (filtered_df["hom_del_frequency"] <= hom_del_selection)
            & (filtered_df["dup_frequency"] <= dup_selection)
        ]

        return filtered_df

    def apply_trio_filters(
        self,
        trio_df: pd.DataFrame,
        selection_index: list,
        selection_father: list,
        selection_mother: list,
        call_list: list,
    ) -> pd.DataFrame:
        """
        Applies the predefined filters onto the trio .cnr DataFrame.

        Args:
            trio_df (pd.DataFrame): DataFrame by merging the index .cnr DataFrame and the parental .cnr files.
            selection_index (list): Calls selected for the index patient.
            selection_father (list): Calls selected for the father.
            selection_mother (list): Calls selected for the mother.
            call_list (list): List of all possible calls.

        Returns:
            pd.DataFrame: Filtered trio DataFrame.
        """
        if not selection_index:
            selection_index = call_list
        if not selection_father:
            selection_father = call_list
        if not selection_mother:
            selection_mother = call_list

        filtered_df = trio_df[
            (trio_df["call"].isin(selection_index))
            & (trio_df["call_f"].isin(selection_father))
            & (trio_df["call_m"].isin(selection_mother))
        ]
        return filtered_df